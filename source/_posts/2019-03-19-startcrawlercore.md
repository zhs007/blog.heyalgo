title: 正式开始CrawlerCore
date: 2019-03-19 16:10:24
tags:
---
这算是我第3次认真的写爬虫框架了（不算打酱油的尝试）。  
前几天又花时间把现在的一些库梳理了一下，感觉现在各种基础库比上次写的时候要完善很多，这次应该能做好点。  

这次没打算用最流行的爬虫语言``python``（以前第一次爬虫框架是``python``写的）。  
主要原因是上次写爬虫框架时，用到了很多``headless chrome``的高阶功能，譬如对js代码设断点，来dump内存数据，感觉很爽，而且这种东西个人觉得几乎没更省事的写法了（花时间分析代码肯定有更优雅的实现方案，但肯定没暴力断点破解来得省事）。  
既然是以``headless chrome``为主，那么当然选官方的封装了（``puppeteer``）。  
既然都用``puppeteer``了，肯定就直接用``nodejs``了。

之所以放弃前个版本，主要是因为上一次的设计太重。上次是个很常规的设计，非常的符合设计美学，各个部分都抽象出来，然后有很多个派生的实现，为了使用起来方便，把数据存储也考虑得很周全，除了csv、json外，自然还有DB的支持，然后还考虑了数据清洗，甚至连分布式的任务分派也放在里面。  

这次的思路比较简单，不用做那么复杂，我要一个轻量级的，跨语言的，只关注数据获取的爬虫框架。  
而且要可以很方便的和其它系统对接，命令行或grpc的，也要能支持分布式，但这部分可以用``Jarvis``来配合完成。  

前期不会考虑特别多，只支持``headless chrome``就好。  

这次还有点不一样的想法，就是注意力会放到具体的业务层上，核心是一个开放的插件体系，最后应该会是一套类插件商店形式的东西。